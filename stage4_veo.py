#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Forecast Pipeline - Stage 4: Veo Video Generation
Generates 5-shot news satire videos from forecasts.

Flow:
1. PROMPT_REPORTER1: Forecast ‚Üí 5-sentence script
2. PROMPT_REPORTER2: Script ‚Üí Veo-formatted prompts with visuals
3. Generate each shot with Veo (with retries + alternates)
4. Concatenate shots into final video
"""

import os
import json
import time
import subprocess
import base64
import io
from typing import Dict, List, Optional
from pathlib import Path
from google import genai
from google.genai import types
from PIL import Image

from utils import (
    log, log_progress, save_response, call_llm,
    extract_json_blocks, is_retryable_error,
    MAX_RETRIES, RETRY_DELAYS, set_current_question
)

# Get configuration from environment
MODEL_REPORTER = os.getenv("MODEL_FC", "").strip()
PROMPT_REPORTER1 = os.getenv("PROMPT_REPORTER1", "").strip()
PROMPT_REPORTER2 = os.getenv("PROMPT_REPORTER2", "").strip()
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "").strip()

# Veo model - CORRECT model name from docs
VEO_MODEL = "veo-3.1-generate-preview"

# Initialize Gemini client
client = None
if GEMINI_API_KEY:
    client = genai.Client(api_key=GEMINI_API_KEY)

# ========================================
# STEP 1: GENERATE SCRIPT (REPORTER1)
# ========================================

def generate_script(forecast: dict) -> Optional[dict]:
    """
    Use PROMPT_REPORTER1 to convert forecast into 5-sentence news script.
    
    Input: forecast (final_payload.json)
    Output: {
        "question_id": "Q1",
        "sentences": [
            {"number": 1, "text": "...", "shot_type": "anchor_lede"},
            {"number": 2, "text": "...", "shot_type": "anchor_vo"},
            {"number": 3, "text": "...", "shot_type": "anchor_vo"},
            {"number": 4, "text": "...", "shot_type": "broll"},
            {"number": 5, "text": "...", "shot_type": "anchor_final"}
        ]
    }
    """
    if not PROMPT_REPORTER1:
        log("[REPORTER1] ‚è≠Ô∏è SKIPPED (PROMPT_REPORTER1 not configured)")
        return None
    
    q_id = forecast.get("metadata", {}).get("question_id", "unknown")
    log(f"[REPORTER1] Generating script for Q {q_id}")
    
    user_payload = json.dumps(forecast, indent=2)
    
    script = None
    response = ""
    
    for attempt in range(1, MAX_RETRIES + 1):
        response = call_llm(
            MODEL_REPORTER,
            PROMPT_REPORTER1,
            user_payload,
            max_tokens=8000,
            timeout=120
        )
        log(f"[REPORTER1] üì• Received {len(response)} chars (attempt {attempt}/{MAX_RETRIES})")
        
        blocks = extract_json_blocks(response, "REPORTER1")
        
        if blocks:
            block = max(blocks, key=len)
            try:
                script = json.loads(block)
                log(f"[REPORTER1] ‚úÖ Valid script extracted")
                break
            except Exception as e:
                log(f"[REPORTER1] ‚ö†Ô∏è JSON parse error: {e}")
        
        if is_retryable_error(response) and attempt < MAX_RETRIES:
            delay = RETRY_DELAYS[min(attempt - 1, len(RETRY_DELAYS) - 1)]
            log(f"[REPORTER1] ‚ö†Ô∏è Retrying in {delay}s...")
            time.sleep(delay)
            continue
    
    if script is None:
        log(f"[REPORTER1] ‚ùå FAILED after {MAX_RETRIES} attempts")
        output_path = os.path.join("out", f"reporter1_q{q_id}_full.txt")
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(response)
        return None
    
    # Save script
    output_path = os.path.join("out", f"script_q{q_id}.json")
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(script, f, indent=2)
    
    log(f"[REPORTER1] üíæ Saved to {output_path}")
    
    return script

# ========================================
# STEP 2: GENERATE VEO PROMPTS (REPORTER2)
# ========================================

def generate_veo_prompts(script: dict) -> Optional[dict]:
    """
    Use PROMPT_REPORTER2 to convert script into Veo-formatted prompts.
    
    Input: script from REPORTER1
    Output: {
        "question_id": "Q1",
        "shots": [
            {
                "shot": 1,
                "vo_text": "Lede sentence 15-20 words",
                "use_reference_image": true,
                "visual_prompts": [
                    {
                        "version": "primary",
                        "prompt": "Full Veo prompt with CONTINUITY LOCK, etc."
                    },
                    {
                        "version": "alternate_1",
                        "prompt": "Sanitized version with 'White House official' instead of 'Trump'"
                    }
                ]
            },
            # ... shots 2-5
        ]
    }
    """
    if not PROMPT_REPORTER2:
        log("[REPORTER2] ‚è≠Ô∏è SKIPPED (PROMPT_REPORTER2 not configured)")
        return None
    
    q_id = script.get("question_id", "unknown")
    log(f"[REPORTER2] Generating Veo prompts for Q {q_id}")
    
    user_payload = json.dumps(script, indent=2)
    
    veo_prompts = None
    response = ""
    
    for attempt in range(1, MAX_RETRIES + 1):
        response = call_llm(
            MODEL_REPORTER,
            PROMPT_REPORTER2,
            user_payload,
            max_tokens=16000,
            timeout=180
        )
        log(f"[REPORTER2] üì• Received {len(response)} chars (attempt {attempt}/{MAX_RETRIES})")
        
        blocks = extract_json_blocks(response, "REPORTER2")
        
        if blocks:
            block = max(blocks, key=len)
            try:
                veo_prompts = json.loads(block)
                log(f"[REPORTER2] ‚úÖ Valid Veo prompts extracted")
                break
            except Exception as e:
                log(f"[REPORTER2] ‚ö†Ô∏è JSON parse error: {e}")
        
        if is_retryable_error(response) and attempt < MAX_RETRIES:
            delay = RETRY_DELAYS[min(attempt - 1, len(RETRY_DELAYS) - 1)]
            log(f"[REPORTER2] ‚ö†Ô∏è Retrying in {delay}s...")
            time.sleep(delay)
            continue
    
    if veo_prompts is None:
        log(f"[REPORTER2] ‚ùå FAILED after {MAX_RETRIES} attempts")
        output_path = os.path.join("out", f"reporter2_q{q_id}_full.txt")
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(response)
        return None
    
    # Save Veo prompts
    output_path = os.path.join("out", f"veo_prompts_q{q_id}.json")
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(veo_prompts, f, indent=2)
    
    log(f"[REPORTER2] üíæ Saved to {output_path}")
    
    return veo_prompts

# ========================================
# STEP 3: LOAD REFERENCE IMAGES
# ========================================

def load_reference_images() -> List[types.VideoGenerationReferenceImage]:
    """
    Upload reference images to File API, then use those for Veo.
    This mimics what the web UI does.
    Returns: List of VideoGenerationReferenceImage objects
    """
    references = []
    
    if not client:
        log("[VEO] ‚ùå Gemini client not initialized")
        return references
    
    image_paths = [
        ("Diane-Medium.png", "anchor"),
    ]
    
    for image_path, name in image_paths:
        if not os.path.exists(image_path):
            log(f"[VEO] ‚ö†Ô∏è Image not found: {image_path} - skipping")
            continue
        
        try:
            log(f"[VEO] Uploading reference image: {image_path}")
            
            # Upload the file to Google's File API (like the web UI does)
            uploaded_file = client.files.upload(path=image_path)
            log(f"[VEO] ‚úÖ Uploaded: {uploaded_file.name}")
            
            # Wait for processing
            while uploaded_file.state.name == "PROCESSING":
                log(f"[VEO] ‚è≥ Waiting for file processing...")
                time.sleep(2)
                uploaded_file = client.files.get(name=uploaded_file.name)
            
            if uploaded_file.state.name == "FAILED":
                log(f"[VEO] ‚ùå File processing failed for {image_path}")
                continue
            
            log(f"[VEO] ‚úÖ File processed: {uploaded_file.name}")
            
            # Now try using the uploaded file as a reference
            # The uploaded file should have the right format
            reference = types.VideoGenerationReferenceImage(
                image=uploaded_file,
                reference_type="asset"
            )
            
            references.append(reference)
            log(f"[VEO] ‚úÖ Loaded reference: {name}")
            
        except Exception as e:
            log(f"[VEO] ‚ùå Failed to load {image_path}: {e}")
            import traceback
            traceback.print_exc()
            continue
    
    return references

# ========================================
# STEP 4: GENERATE SINGLE SHOT WITH RETRIES
# ========================================

def generate_shot_with_retries(shot_data: dict, all_references: List[types.VideoGenerationReferenceImage], q_id: str) -> Optional[str]:
    """
    Generate a single shot with retry logic and alternate prompts.
    
    Returns: Path to generated MP4 file, or None if all attempts failed
    """
    shot_num = shot_data.get("shot", 0)
    visual_prompts = shot_data.get("visual_prompts", [])
    use_reference = shot_data.get("use_reference_image", False)
    
    if not visual_prompts:
        log(f"[VEO] ‚ö†Ô∏è Shot {shot_num} has no visual prompts - skipping")
        return None
    
    if not client:
        log(f"[VEO] ‚ùå Gemini client not initialized")
        return None
    
    log(f"[VEO] Generating shot {shot_num} for Q {q_id}")
    
    # Try each prompt version
    for prompt_data in visual_prompts:
        version = prompt_data.get("version", "unknown")
        prompt_text = prompt_data.get("prompt", "")
        
        if not prompt_text:
            continue
        
        log(f"[VEO] Trying shot {shot_num} - version '{version}'")
        
        # Try this version up to 2 times
        for attempt in range(1, 3):
            try:
                log(f"[VEO] Submitting generation request for shot {shot_num}...")
                
                # Use reference images if requested AND available
                if use_reference and all_references:
                    log(f"[VEO] Using {len(all_references)} reference image(s) for shot {shot_num}")
                    operation = client.models.generate_videos(
                        model=VEO_MODEL,
                        prompt=prompt_text,
                        config=types.GenerateVideosConfig(
                            reference_images=all_references,
                        ),
                    )
                else:
                    # Text-to-video only
                    operation = client.models.generate_videos(
                        model=VEO_MODEL,
                        prompt=prompt_text,
                    )
                
                # Poll for completion (from docs)
                log(f"[VEO] ‚è≥ Waiting for shot {shot_num} to generate (2-5 minutes)...")
                
                max_wait_time = 600  # 10 minutes max
                elapsed = 0
                poll_interval = 10  # Check every 10 seconds
                
                while not operation.done:
                    if elapsed >= max_wait_time:
                        log(f"[VEO] ‚è±Ô∏è Shot {shot_num} timed out after {max_wait_time}s")
                        break
                    
                    time.sleep(poll_interval)
                    elapsed += poll_interval
                    log(f"[VEO] ‚è≥ Still waiting... ({elapsed}s elapsed)")
                    
                    # Refresh operation status
                    operation = client.operations.get(operation)
                
                if not operation.done:
                    log(f"[VEO] ‚è±Ô∏è Shot {shot_num} timed out")
                    continue
                
                # Download the generated video
                generated_video = operation.response.generated_videos[0]
                
                output_filename = f"shot_{shot_num}_q{q_id}.mp4"
                output_path = os.path.join("out", output_filename)
                
                # Download and save
                client.files.download(file=generated_video.video)
                generated_video.video.save(output_path)
                
                log(f"[VEO] ‚úÖ Shot {shot_num} saved to {output_path}")
                return output_path
                
            except Exception as e:
                log(f"[VEO] ‚ö†Ô∏è Shot {shot_num} attempt {attempt}/2 failed: {e}")
                import traceback
                traceback.print_exc()
                if attempt < 2:
                    time.sleep(5)
                    continue
        
        log(f"[VEO] ‚ö†Ô∏è Shot {shot_num} version '{version}' failed - trying next version")
    
    log(f"[VEO] ‚ùå Shot {shot_num} - all versions failed")
    return None

# ========================================
# STEP 5: CONCATENATE VIDEOS
# ========================================

def concatenate_videos(shot_files: List[str], output_filename: str) -> Optional[str]:
    """
    Concatenate multiple MP4 files into one video using ffmpeg.
    
    Returns: Path to final video or None if failed
    """
    if not shot_files:
        log("[VEO] ‚ùå No shots to concatenate")
        return None
    
    log(f"[VEO] Concatenating {len(shot_files)} shots...")
    
    try:
        # Create concat list file
        concat_list_path = os.path.join("out", "concat_list.txt")
        with open(concat_list_path, 'w') as f:
            for shot_file in shot_files:
                # Use absolute path or relative from out/ directory
                f.write(f"file '{os.path.basename(shot_file)}'\n")
        
        # Run ffmpeg
        output_path = os.path.join("out", output_filename)
        result = subprocess.run([
            'ffmpeg',
            '-f', 'concat',
            '-safe', '0',
            '-i', 'concat_list.txt',
            '-c', 'copy',
            output_filename
        ], cwd='out', capture_output=True, text=True)
        
        if result.returncode != 0:
            log(f"[VEO] ‚ùå ffmpeg failed: {result.stderr}")
            return None
        
        log(f"[VEO] ‚úÖ Final video saved to {output_path}")
        
        # Clean up concat list
        os.remove(concat_list_path)
        
        return output_path
    
    except Exception as e:
        log(f"[VEO] ‚ùå Concatenation failed: {e}")
        import traceback
        traceback.print_exc()
        return None

# ========================================
# MAIN: RUN COMPLETE STAGE 4 FOR ONE QUESTION
# ========================================

def run_stage4_for_question(forecast: dict) -> Optional[str]:
    """
    Complete Veo video generation pipeline for one question.
    
    Returns: Path to final video MP4, or None if failed
    """
    q_id = forecast.get("metadata", {}).get("question_id", "unknown")
    
    log_progress(f"üé¨ STARTING STAGE 4 FOR Q {q_id}")
    
    # Step 1: Generate script
    script = generate_script(forecast)
    if not script:
        return None
    
    # Step 2: Generate Veo prompts
    veo_prompts = generate_veo_prompts(script)
    if not veo_prompts:
        return None
    
    # Step 3: Load reference images (once per question)
    all_references = load_reference_images()
    if not all_references:
        log("[VEO] ‚ö†Ô∏è No reference images loaded - anchor may be inconsistent")
    
    # Step 4: Generate each shot
    shots = veo_prompts.get("shots", [])
    generated_shots = []
    
    for shot_data in shots:
        shot_file = generate_shot_with_retries(shot_data, all_references, q_id)
        if shot_file:
            generated_shots.append(shot_file)
        else:
            log(f"[VEO] ‚ö†Ô∏è Skipping failed shot {shot_data.get('shot')}")
    
    if not generated_shots:
        log(f"[VEO] ‚ùå No shots generated for Q {q_id}")
        return None
    
    # Step 5: Concatenate shots
    final_video = concatenate_videos(generated_shots, f"video_q{q_id}.mp4")
    
    if final_video:
        log_progress(f"‚úÖ STAGE 4 COMPLETE FOR Q {q_id}: {final_video}")
    
    return final_video

# ========================================
# RUN STAGE 4 FOR ALL FORECASTS
# ========================================

def run_stage4(forecasts: List[dict]) -> Optional[Dict[str, str]]:
    """
    Run Stage 4 for all forecasts sequentially.
    
    Returns: Dict mapping question IDs to video paths
    """
    log_progress("üé¨ STARTING STAGE 4: VEO VIDEO GENERATION")
    
    # Reset to root directory
    set_current_question(None)
    
    if not PROMPT_REPORTER1 or not PROMPT_REPORTER2:
        log("[VEO] ‚è≠Ô∏è SKIPPED (PROMPT_REPORTER1 or PROMPT_REPORTER2 not configured)")
        return {"skipped": "Prompts not configured"}
    
    if not GEMINI_API_KEY:
        log("[VEO] ‚è≠Ô∏è SKIPPED (GEMINI_API_KEY not configured)")
        return {"skipped": "Gemini API key not configured"}
    
    if not forecasts:
        log("[VEO] ‚ö†Ô∏è No forecasts provided")
        return None
    
    videos = {}
    
    for forecast in forecasts:
        q_id = forecast.get("metadata", {}).get("question_id", "unknown")
        
        video_path = run_stage4_for_question(forecast)
        
        if video_path:
            videos[q_id] = video_path
        else:
            log(f"[VEO] ‚ö†Ô∏è Failed to generate video for Q {q_id}")
    
    log_progress(f"‚úÖ STAGE 4 COMPLETE: {len(videos)} videos generated")
    
    return videos if videos else None

# ========================================
# END OF STAGE4_VEO
# ========================================
